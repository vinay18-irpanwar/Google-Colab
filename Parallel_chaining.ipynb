{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOO+A+KpZy4SgOs+M9sn7C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinay18-irpanwar/Google-Colab/blob/main/Parallel_chaining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XXvJytV6zbow",
        "outputId": "26b21b1a-8105-4c77-b72a-0e94c1ab63c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.79)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"pune\""
      ],
      "metadata": {
        "id": "U7siaAVszvq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#without LLM"
      ],
      "metadata": {
        "id": "uFKhYj726jWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word(text):\n",
        "  words=text.split(\" \")\n",
        "  return f\"no of words in text is {len(words)}\"\n",
        "print(word(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llT3WEvJ0MZu",
        "outputId": "85450d0a-cec1-47e1-f0bb-de8a1dedce4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no of words in text is 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def character(text):\n",
        "  return f\"no of character in text is {len(text)}\"\n",
        "print(character(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3wBkL0Z0iia",
        "outputId": "492d62b3-c48c-493f-93c3-c6254a7dba2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no of character in text is 51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now i want to run both fun parallel\n",
        "\n",
        "#parallel chaining\n",
        "\n"
      ],
      "metadata": {
        "id": "3SZpNmXG25_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableParallel\n",
        "\n",
        "#if fun is not runnable then we use runnablelambda\n",
        "\"\"\"word_count=RunnableLambda(word)\n",
        "character_count=RunnableLambda(character)\"\"\"\n",
        "chain_parallel=RunnableParallel({\"word\":word,\"character\":character})\n",
        "res=chain_parallel.invoke(text)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGIw-xq23Hpe",
        "outputId": "4fe42efb-4cc7-4078-cbcc-2cfa11747bcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'word': 'no of words in text is 8', 'character': 'no of character in text is 51'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#web2post using langchain"
      ],
      "metadata": {
        "id": "axl9cbiN_8za"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#with LLM"
      ],
      "metadata": {
        "id": "AtrMGbO26mpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tavily-python langchain langchain_google_genai  #quite mode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "TOiJ32yZ6ovi",
        "outputId": "d209b27f-b531-4eef-dd39-157d47d64dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tavily-python in /usr/local/lib/python3.12/dist-packages (0.7.13)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain_google_genai in /usr/local/lib/python3.12/dist-packages (3.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from tavily-python) (2.32.4)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tavily-python) (0.12.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from tavily-python) (0.28.1)\n",
            "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
            "  Downloading langchain_core-0.3.80-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<1.0.0,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (0.9.0)\n",
            "INFO: pip is looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-3.0.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_google_genai-3.0.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_google_genai-3.0.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain_google_genai-3.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain_google_genai-2.1.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain_google_genai) (2.28.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain_google_genai) (2.38.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain_google_genai) (1.76.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain_google_genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain_google_genai) (5.29.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->tavily-python) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx->tavily-python) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->tavily-python) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx->tavily-python) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.11.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain_google_genai) (1.72.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain_google_genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain_google_genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->tavily-python) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain_google_genai) (0.6.1)\n",
            "Downloading langchain_google_genai-2.1.12-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.80-py3-none-any.whl (450 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m450.8/450.8 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-core, langchain_google_genai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.0.7\n",
            "    Uninstalling langchain-core-1.0.7:\n",
            "      Successfully uninstalled langchain-core-1.0.7\n",
            "  Attempting uninstall: langchain_google_genai\n",
            "    Found existing installation: langchain-google-genai 3.1.0\n",
            "    Uninstalling langchain-google-genai-3.1.0:\n",
            "      Successfully uninstalled langchain-google-genai-3.1.0\n",
            "Successfully installed langchain-core-0.3.80 langchain_google_genai-2.1.12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "langchain_core"
                ]
              },
              "id": "cb7e484b5acd4d8581142b25d0d1bae9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_search=\"pune\""
      ],
      "metadata": {
        "id": "kshZ3kS7CFtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###tavily search"
      ],
      "metadata": {
        "id": "5P1cCv-tCNW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  # To install: pip install tavily-python\n",
        "from tavily import TavilyClient\n",
        "client = TavilyClient(\"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\")\n",
        "def web(user_search):\n",
        "\n",
        "\n",
        "    response = client.search(\n",
        "           query=user_search,\n",
        "           include_answer=\"advanced\"\n",
        "    )\n",
        "    return response.get(\"answer\")\n",
        "ans = web(user_search)"
      ],
      "metadata": {
        "id": "-MW3Vs1NCS68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###chaining"
      ],
      "metadata": {
        "id": "amyMzWQbDZpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from google.colab import userdata\n"
      ],
      "metadata": {
        "id": "deOAqxyV8d4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM\n"
      ],
      "metadata": {
        "id": "2HaEAC3RUFd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LLM=ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    google_api_key=userdata.get('lang')\n",
        ")"
      ],
      "metadata": {
        "id": "IAfGCNljQE8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "templates"
      ],
      "metadata": {
        "id": "VbsxZ0paUIlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary_prompt=PromptTemplate(template=\"Summarize the following text into a clear, concise overview while keeping all key points and removing any fluff. Maintain the original meaning refere content from{ans}\",input_varable=[\"ans\"])\n",
        "linkdin_prompt=PromptTemplate(\n",
        "    template=\"act as a linkdin post generator and generate a butiful post by refering content :- {summary1}\",\n",
        "    input_varable=[\"summary1\"])\n",
        "fackbook_prompt=PromptTemplate(\n",
        "    template=\"act as a fackbook post generator and generate a butiful  post on {summary2}\",\n",
        "    input_varable=[\"summary2\"])\n",
        "twitter_prompt=PromptTemplate(\n",
        "    template=\"act as a twitter post creator and generate a interactive post on {summary3}\",\n",
        "    input_varable=[\"summary3\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "Z2Ia-AhqQkpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "summary result\n"
      ],
      "metadata": {
        "id": "degV2SYaUK0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summaryy=summary_prompt.format(ans=ans)\n",
        "report=LLM.invoke(summaryy)\n",
        "\n"
      ],
      "metadata": {
        "id": "86b8i3E8UDzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "chains\n"
      ],
      "metadata": {
        "id": "IUDnkAICVA2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "linkdin_chain=linkdin_prompt | LLM | StrOutputParser()\n",
        "fackbook_chain=fackbook_prompt | LLM | StrOutputParser()\n",
        "twitter_chain=twitter_prompt | LLM | StrOutputParser()\n"
      ],
      "metadata": {
        "id": "6nA9FtmAS2YS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "paralle; chaining"
      ],
      "metadata": {
        "id": "cLm-fGW0V_sE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableParallel,RunnableLambda"
      ],
      "metadata": {
        "id": "X5Vw8Tp0VAGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "link=linkdin_prompt | LLM | StrOutputParser()\n",
        "re=link.invoke(report)\n",
        "print(re)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzGw8xrwZib8",
        "outputId": "10196ab3-2eff-41df-db30-2079350abcc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a beautiful LinkedIn post inspired by the content you provided:\n",
            "\n",
            "---\n",
            "\n",
            "‚ú® Ever wondered which Indian city perfectly blends rich heritage with cutting-edge education and dynamic growth? Look no further than **Pune**! ‚ú®\n",
            "\n",
            "Affectionately known as the \"Queen of the Deccan\" and the cultural capital of the Maratha region, Pune is a true powerhouse. It's proudly earned the moniker \"Oxford and Cambridge of India\" thanks to its incredible concentration of world-class colleges and research institutes, making it a beacon for talent and innovation. üéìüí°\n",
            "\n",
            "As India's ninth-largest city, home to over three million residents, Pune isn't just big ‚Äì it's booming! Serving as a crucial administrative headquarters, the city is a hub of activity and opportunity.\n",
            "\n",
            "But beyond its academic and economic prowess, Pune captivates with its vibrant culture, historic sites, and a rapidly expanding tourism infrastructure that invites exploration. It's a city where tradition meets tomorrow, offering something for everyone.\n",
            "\n",
            "Have you experienced the unique charm and energy of Pune? Share your thoughts and experiences in the comments! üëá\n",
            "\n",
            "#Pune #QueenOfTheDeccan #EducationalHub #India #Culture #Innovation #HigherEducation #Maharashtra #SmartCity #TravelIndia #CityOfOpportunity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parallel_chain=RunnableParallel(\n",
        "    {\"linkdin\":linkdin_chain,\"fackbook\":fackbook_chain,\"twitter\":twitter_chain}\n",
        ")\n",
        "r=parallel_chain.invoke({\"summary1\":report,\"summary2\":report,\"summary3\":report})\n",
        "print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OleYFBpV-9f",
        "outputId": "446eb95b-0018-490e-ded6-3a623592392b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'linkdin': 'Okay, I\\'ll provide a template that you can easily adapt by inserting your specific [summary].\\n\\n---\\n\\nHere\\'s a professional LinkedIn post structure, ready for your content:\\n\\n---\\n\\n**LinkedIn Post Template:**\\n\\nWhat if the most powerful tool in your professional arsenal isn\\'t a complex strategy or a cutting-edge technology, but something far more fundamental?\\n\\nIn today\\'s dynamic landscape, **[Insert your summary here, e.g., \"the critical role of adaptive learning in professional development is becoming undeniably clear, directly impacting career resilience and innovation.\"]**\\n\\nI\\'ve observed countless times how [brief story or value point related to your summary]. For instance, [elaborate briefly, e.g., \"when individuals are empowered to continuously upskill and reskill, not only do they navigate change with greater confidence, but they also bring fresh perspectives that drive organizational growth. It\\'s not just about acquiring new knowledge; it\\'s about cultivating a mindset of continuous curiosity and practical application.\"] This isn\\'t merely a trend; it\\'s a strategic imperative that fosters deeper engagement, enhances problem-solving capabilities, and ultimately, builds a more robust and future-ready workforce.\\n\\nWhat specific actions or strategies have you found most effective in [relate to your summary, e.g., \"fostering a culture of continuous learning or adapting to significant professional shifts?\"] I\\'d love to hear your perspectives and experiences in the comments below.\\n\\n# [RelevantHashtag1] # [RelevantHashtag2] # [RelevantHashtag3] # [YourIndustryTag] # [CallToActionFocus]\\n\\n---\\n\\n**Example filled in with a hypothetical summary:**\\n\\nLet\\'s use the summary: *\"The critical role of cross-functional collaboration in driving innovation and achieving strategic business objectives.\"*\\n\\n---\\n\\n**Example Post:**\\n\\nWhat if the most powerful tool in your professional arsenal isn\\'t a complex strategy or a cutting-edge technology, but something far more fundamental?\\n\\nIn today\\'s dynamic landscape, **the critical role of cross-functional collaboration in driving innovation and achieving strategic business objectives is becoming undeniably clear.**\\n\\nI\\'ve observed countless times how bringing diverse expertise together can unlock solutions that siloed teams simply can\\'t. For instance, when marketing, product development, and customer service teams truly collaborate from conception to launch, the result isn\\'t just a better product, but a more cohesive market entry and a superior customer experience. It\\'s not just about sharing information; it\\'s about synthesizing different viewpoints, challenging assumptions, and co-creating value that resonates deeply with the market. This isn\\'t merely a trend; it\\'s a strategic imperative that fosters deeper engagement, enhances problem-solving capabilities, and ultimately, builds a more robust and future-ready organization.\\n\\nWhat specific actions or strategies have you found most effective in fostering genuine cross-functional collaboration within your teams or organization? I\\'d love to hear your perspectives and experiences in the comments below.\\n\\n#Collaboration #Innovation #Teamwork #BusinessStrategy #Leadership #CrossFunctionalTeams\\n\\n---', 'fackbook': 'Okay, here\\'s a friendly, conversational Facebook post template you can easily adapt! Just drop your summary right in:\\n\\n---\\n\\nHey everyone! üëã Just wanted to pop on here and share some exciting news about [**insert your summary here, e.g., \"our new project,\" \"a recent achievement,\" \"an upcoming event\"**]!\\n\\nWe\\'re absolutely thrilled about this ‚ú® and think it\\'s going to be really impactful/fun/helpful [**choose adjective that fits your summary**]. We\\'d love to hear your initial thoughts! What aspect of this are you most excited to learn more about, or how do you think it might benefit you?', 'twitter': 'Okay, I can help you craft that! Just replace `[TOPIC]` with your desired subject.\\n\\n---\\n\\n**Here\\'s your template and an example:**\\n\\n\"Write a short, high-engagement Twitter post about **[TOPIC]**. Use a punchy tone, trending hashtags, and no more than 240 characters. Include an emoji only if it feels natural.\\n\\n---\\n\\n**Example for the topic: \"The Future of Remote Work\"**\\n\\n\"Remote work isn\\'t just a perk anymore, it\\'s the new standard. üöÄ Ditch the commute, embrace flexibility, and redefine productivity. The office is wherever you are! #FutureOfWork #RemoteRevolution #WorkFromAnywhere\"\\n\\n---\\n\\n**Why this works:**\\n\\n*   **Punchy Tone:** Starts with a bold statement (\"new standard\"), uses active verbs (\"Ditch,\" \"embrace,\" \"redefine\").\\n*   **High-Engagement:** Challenges old norms, offers clear benefits, and ends with an empowering statement.\\n*   **Trending Hashtags:** `#FutureOfWork`, `#RemoteRevolution`, `#WorkFromAnywhere` are relevant and widely used.\\n*   **Character Count:** 198/240 characters ‚Äì well within limits, leaving room for retweets/comments.\\n*   **Emoji:** The `üöÄ` (rocket) naturally conveys progress, speed, and future-forward thinking.'}\n"
          ]
        }
      ]
    }
  ]
}